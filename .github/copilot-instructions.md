You are a senior backend engineer and NLP engineer.

Your task is to design and implement a Django-based web application called
â€œKTU Previous Year Question Priority Analyzerâ€.

This is NOT a toy project and NOT an LLM-based system.
Do NOT use OpenAI, GPT, or any paid API.
Use only classical NLP + sentence embeddings where explicitly required.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CORE GOAL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
The system must allow WEB USERS (not admin) to upload multiple KTU previous-year
question paper PDFs and automatically generate MODULE-WISE PDFs that contain:

1) A COMPLETE question bank (all extracted questions, module-wise)
2) A PRIORITY ANALYSIS section that ranks REPEATED TOPICS based on:
   - Frequency across years
   - Marks weight
   - Combined Part A + Part B contribution
   - Confidence score (year coverage)

Priority classification is the CORE feature.
If priority is removed, the project becomes useless.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCOPE & CONSTRAINTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ KTU-specific exam pattern (fixed rules)
â€¢ Temporary job-based processing (NO permanent storage of user PDFs)
â€¢ Each upload session must be isolated using a job_id (UUID)
â€¢ Data must be auto-deleted after job completion or timeout
â€¢ Deterministic rules wherever possible
â€¢ AI ONLY for semantic similarity (topic clustering)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USER FLOW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. User opens website
2. User uploads MULTIPLE PYQ PDFs (same subject)
3. System creates a job_id and temporary workspace
4. System analyzes PDFs
5. System generates 5 module-wise PDFs
6. User downloads PDFs
7. System auto-cleans all job data

NO login system is required.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TECH STACK (MANDATORY)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Backend:
â€¢ Django
â€¢ Python

PDF Processing:
â€¢ pdfplumber (text-based PDFs)
â€¢ PyMuPDF + pytesseract + OpenCV (scanned PDFs)

NLP / ML:
â€¢ sentence-transformers/all-MiniLM-L6-v2
â€¢ scikit-learn
â€¢ HDBSCAN
â€¢ NumPy

PDF Generation:
â€¢ ReportLab OR WeasyPrint

Frontend:
â€¢ Django templates
â€¢ Minimal JS
â€¢ Simple CSS

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DETAILED WORKFLOW (MUST FOLLOW EXACTLY)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE 1 â€” USER UPLOAD
â€¢ Accept multiple PDFs from user
â€¢ Validate file type and size
â€¢ Generate job_id (UUID)
â€¢ Create /media/jobs/<job_id>/

PHASE 2 â€” PDF TYPE DETECTION
â€¢ Detect whether PDF is text-based or scanned
â€¢ Extract raw text (store unchanged)
â€¢ Extract images separately

PHASE 3 â€” QUESTION SEGMENTATION (RULE-BASED)
â€¢ Detect PART A and PART B
â€¢ Extract logical questions:
  - Question number
  - Full question text
  - Marks
  - Year
  - Part (A or B)
â€¢ Handle OR questions and sub-parts correctly
â€¢ Each logical question = one semantic unit

PHASE 4 â€” MODULE MAPPING (RULE-BASED)
Use fixed KTU rules:
Qn 1â€“2   â†’ Module 1
Qn 3â€“4   â†’ Module 2
Qn 5â€“6   â†’ Module 3
Qn 7â€“8   â†’ Module 4
Qn 9â€“10  â†’ Module 5
Qn 11â€“12 â†’ Module 1
Qn 13â€“14 â†’ Module 2
Qn 15â€“16 â†’ Module 3
Qn 17â€“18 â†’ Module 4
Qn 19â€“20 â†’ Module 5

PHASE 5 â€” QUESTION NORMALIZATION
â€¢ Create a separate normalized text field
â€¢ Remove numbering, marks, year references
â€¢ Preserve academic meaning
â€¢ DO NOT overwrite raw text

PHASE 6 â€” EMBEDDING GENERATION
â€¢ Combine Part A + Part B questions
â€¢ Generate embeddings module-wise
â€¢ Cache embeddings per job

Model:
sentence-transformers/all-MiniLM-L6-v2

PHASE 7 â€” TOPIC CLUSTERING (CORE AI)
â€¢ Perform clustering PER MODULE
â€¢ Use HDBSCAN
â€¢ Each cluster = one exam topic
â€¢ Noise questions must be allowed

PHASE 8 â€” PRIORITY SCORING (CORE FEATURE)
For each topic cluster, compute:

â€¢ Frequency = number of DISTINCT YEARS appeared
â€¢ Average Marks
â€¢ Part A count
â€¢ Part B count

Priority Score Formula:
Priority Score = (2 Ã— Frequency) + (Average Marks)

PHASE 9 â€” CONFIDENCE SCORE (MANDATORY EXTRA FEATURE)
Compute:
Confidence (%) =
(Number of years topic appeared Ã· Total years uploaded) Ã— 100

PHASE 10 â€” PRIORITY TIERS
Assign tiers:
â€¢ Tier 1 â€“ Very High Priority
â€¢ Tier 2 â€“ High Priority
â€¢ Tier 3 â€“ Medium Priority
â€¢ Tier 4 â€“ Low Priority

PHASE 11 â€” MODULE-WISE PDF GENERATION
Generate ONE PDF PER MODULE.

Each PDF must contain:

SECTION A â€” COMPLETE QUESTION BANK
â€¢ PART A (year-wise grouping)
â€¢ PART B (year-wise grouping)
â€¢ Preserve question text, marks, diagrams

SECTION B â€” REPEATED QUESTION ANALYSIS
â€¢ Tier-wise topics
â€¢ Repetition count
â€¢ Appearing years
â€¢ Confidence score
â€¢ Part A vs Part B contribution

FINAL STUDY PRIORITY ORDER
â€¢ Linear list from Tier 1 â†’ Tier 4

The PDF structure must match standard KTU exam formatting.

PHASE 12 â€” USER DELIVERY
â€¢ Show download buttons for Module 1â€“5 PDFs

PHASE 13 â€” AUTO CLEANUP
â€¢ Delete all job data after download or timeout

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ARCHITECTURE REQUIREMENTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Separate modules for:
  - PDF extraction
  - Question parsing
  - Module mapping
  - Embeddings
  - Clustering
  - Priority scoring
  - PDF generation
â€¢ DO NOT put ML logic inside Django views
â€¢ Views must only orchestrate workflow



â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OUTPUT EXPECTATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Provide:
1. Django project structure
2. Models / data structures (job-based)
3. Views + URL flow
4. Core pipeline pseudo-code
5. Notes on where each phase is implemented



# ğŸ¥‡ SELECTED EXTRA FEATURE (LOCKED)

## âœ… **Confidence Score + Part-A / Part-B Contribution (COMBINED FEATURE)**

This is the **highest ROI feature** you can add.
It upgrades your priority system from *ranking* â†’ *quantified intelligence*.

No ML risk. No hype. Pure logic.

---

# ğŸ§  WHAT THIS FEATURE ACTUALLY ADDS

For **each PRIORITY TOPIC**, you will now show:

1. **Priority Tier** (already there)
2. **Confidence %** (NEW)
3. **Part A vs Part B split** (NEW)

This answers the studentâ€™s real questions:

* *How sure is this topic?*
* *Is it usually short notes or long answers?*

Most projects NEVER answer this.

---

# ğŸ“ EXACT DEFINITIONS (NO AMBIGUITY)

## 1ï¸âƒ£ Confidence Score

### Formula (simple, defendable):

```
Confidence (%) =
(Number of distinct years topic appeared Ã·
 Total years uploaded) Ã— 100
```

### Example:

* Topic appeared in **6 out of 7 years**
* Confidence = **85.7%**

This is **not guessing**.
This is probability from historical data.

---

## 2ï¸âƒ£ Part A vs Part B Contribution

For each topic cluster:

```
Part A appearances = count of questions from Part A
Part B appearances = count of questions from Part B
```

Then display:

```
Appears as:
â€¢ Part A: 4 times
â€¢ Part B: 3 times
```

This is **exam intelligence**, not AI fluff.

---

# ğŸ§© WHERE THIS FITS IN YOUR WORKFLOW

We are NOT adding a new phase.
We are **enhancing Phase 9 (Priority Scoring)**.

---

## ğŸ” UPDATED PHASE 9 â€” PRIORITY SCORING (FINAL)

For each **topic cluster**:

### Step 9.1 â€” Frequency

* Count distinct years (unchanged)

### Step 9.2 â€” Marks influence

* Average marks (unchanged)

### ğŸ”¥ Step 9.3 â€” NEW: Part-wise contribution

* Count Part A questions
* Count Part B questions

### ğŸ”¥ Step 9.4 â€” NEW: Confidence

* Use total years uploaded in job

### Step 9.5 â€” Priority score

```
Priority Score = (2 Ã— Frequency) + (Avg Marks)
```

Tier assignment stays same.

Nothing breaks. Everything improves.

---

# ğŸ–¨ï¸ HOW IT APPEARS IN THE OUTPUT PDF

### Example (TOP PRIORITY topic):

```
1. Disaster Risk Management (Framework + Core Elements)

Appears in: 2021, 2022, 2023, 2024, 2025
Repetition count: 6
Confidence: 85%

Appears as:
â€¢ Part A: 2 times
â€¢ Part B: 4 times

â†’ Very high probability long-answer topic.
```
